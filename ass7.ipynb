{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Analytics\n",
    "\n",
    "\n",
    "1. Extract Sample document and apply following document preprocessing methods:\n",
    "Tokenization, POS Tagging, stop words removal, Stemming and Lemmatization. 2. Create representation of documents by calculating Term Frequency and Inverse\n",
    "DocumentFrequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics.pairwise import cosine_similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I think Amazon is making a great effort in adding engaging content but I can’t get past the ugly interface. It’s not as intuitive as other competing streaming services and if it weren’t lumped in with my Prime membership, I wouldn’t pay for the stand-alone service.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'think', 'amazon', 'is', 'making', 'a', 'great', 'effort', 'in', 'adding', 'engaging', 'content', 'but', 'i', 'can', '’', 't', 'get', 'past', 'the', 'ugly', 'interface', '.', 'it', '’', 's', 'not', 'as', 'intuitive', 'as', 'other', 'competing', 'streaming', 'services', 'and', 'if', 'it', 'weren', '’', 't', 'lumped', 'in', 'with', 'my', 'prime', 'membership', ',', 'i', 'wouldn', '’', 't', 'pay', 'for', 'the', 'stand-alone', 'service', '.']\n",
      "['I think Amazon is making a great effort in adding engaging content but I can’t get past the ugly interface.', 'It’s not as intuitive as other competing streaming services and if it weren’t lumped in with my Prime membership, I wouldn’t pay for the stand-alone service.']\n"
     ]
    }
   ],
   "source": [
    "# word tokenization \n",
    "tokens = nltk.word_tokenize(text.lower()) \n",
    "print(tokens)\n",
    "\n",
    "sentence_token = nltk.sent_tokenize(text) \n",
    "print(sentence_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['think', 'amazon', 'making', 'great', 'effort', 'adding', 'engaging', 'content', '’', 'get', 'past', 'ugly', 'interface', '.', '’', 'intuitive', 'competing', 'streaming', 'services', '’', 'lumped', 'prime', 'membership', ',', '’', 'pay', 'stand-alone', 'service', '.']\n"
     ]
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english') \n",
    "text_cleaned = [] \n",
    "\n",
    "for word in tokens: \n",
    "    if word not in stopwords: \n",
    "        text_cleaned.append(word)  \n",
    "print(text_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['think', 'amazon', 'make', 'great', 'effort', 'ad', 'engag', 'content', '’', 'get', 'past', 'ugli', 'interfac', '.', '’', 'intuit', 'compet', 'stream', 'servic', '’', 'lump', 'prime', 'membership', ',', '’', 'pay', 'stand-alon', 'servic', '.']\n"
     ]
    }
   ],
   "source": [
    "# stemming \n",
    "\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "text_stemmed = []\n",
    "\n",
    "for word in text_cleaned:\n",
    "    text_stemmed.append(stemmer.stem(word)) \n",
    "\n",
    "print(text_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('think', 'VB'), ('amazon', 'NN'), ('making', 'VBG'), ('great', 'JJ'), ('effort', 'NN'), ('adding', 'VBG'), ('engaging', 'VBG'), ('content', 'NN'), ('’', 'NNP'), ('get', 'VB'), ('past', 'JJ'), ('ugly', 'RB'), ('interface', 'NN'), ('.', '.'), ('’', 'JJ'), ('intuitive', 'JJ'), ('competing', 'VBG'), ('streaming', 'VBG'), ('services', 'NNS'), ('’', 'NNP'), ('lumped', 'VBD'), ('prime', 'JJ'), ('membership', 'NN'), (',', ','), ('’', 'JJ'), ('pay', 'NN'), ('stand-alone', 'NN'), ('service', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "pos_tag = nltk.pos_tag(text_cleaned) \n",
    "\n",
    "print(pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['think', 'amazon', 'making', 'great', 'effort', 'adding', 'engaging', 'content', '’', 'get', 'past', 'ugly', 'interface', '.', '’', 'intuitive', 'competing', 'streaming', 'service', '’', 'lumped', 'prime', 'membership', ',', '’', 'pay', 'stand-alone', 'service', '.']\n"
     ]
    }
   ],
   "source": [
    "# lemmatization \n",
    "lemmatizer = nltk.stem.WordNetLemmatizer() \n",
    "text_lemmatized = []\n",
    "\n",
    "for word in text_cleaned:\n",
    "    text_lemmatized.append(lemmatizer.lemmatize(word))\n",
    "    \n",
    "print(text_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'think': 34, 'amazon': 2, 'is': 18, 'making': 21, 'great': 13, 'effort': 9, 'in': 15, 'adding': 0, 'engaging': 10, 'content': 8, 'but': 5, 'can': 6, 'get': 12, 'past': 26, 'the': 33, 'ugly': 35, 'interface': 16, 'it': 19, 'not': 24, 'as': 4, 'intuitive': 17, 'other': 25, 'competing': 7, 'streaming': 32, 'services': 30, 'and': 3, 'if': 14, 'weren': 36, 'lumped': 20, 'with': 37, 'my': 23, 'prime': 28, 'membership': 22, 'wouldn': 38, 'pay': 27, 'for': 11, 'stand': 31, 'alone': 1, 'service': 29}\n"
     ]
    }
   ],
   "source": [
    "vector = TfidfVectorizer(analyzer='word', use_idf=True, smooth_idf=True) \n",
    "\n",
    "text = [\"I think Amazon is making a great effort in adding engaging content but I can’t get past the ugly interface. It’s not as intuitive as other competing streaming services and if it weren’t lumped in with my Prime membership, I wouldn’t pay for the stand-alone service.\",] \n",
    "out = vector.fit(text)\n",
    "print(out.vocabulary_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 29)\t0.14002800840280097\n",
      "  (0, 1)\t0.14002800840280097\n",
      "  (0, 31)\t0.14002800840280097\n",
      "  (0, 11)\t0.14002800840280097\n",
      "  (0, 27)\t0.14002800840280097\n",
      "  (0, 38)\t0.14002800840280097\n",
      "  (0, 22)\t0.14002800840280097\n",
      "  (0, 28)\t0.14002800840280097\n",
      "  (0, 23)\t0.14002800840280097\n",
      "  (0, 37)\t0.14002800840280097\n",
      "  (0, 20)\t0.14002800840280097\n",
      "  (0, 36)\t0.14002800840280097\n",
      "  (0, 14)\t0.14002800840280097\n",
      "  (0, 3)\t0.14002800840280097\n",
      "  (0, 30)\t0.14002800840280097\n",
      "  (0, 32)\t0.14002800840280097\n",
      "  (0, 7)\t0.14002800840280097\n",
      "  (0, 25)\t0.14002800840280097\n",
      "  (0, 17)\t0.14002800840280097\n",
      "  (0, 4)\t0.28005601680560194\n",
      "  (0, 24)\t0.14002800840280097\n",
      "  (0, 19)\t0.28005601680560194\n",
      "  (0, 16)\t0.14002800840280097\n",
      "  (0, 35)\t0.14002800840280097\n",
      "  (0, 33)\t0.28005601680560194\n",
      "  (0, 26)\t0.14002800840280097\n",
      "  (0, 12)\t0.14002800840280097\n",
      "  (0, 6)\t0.14002800840280097\n",
      "  (0, 5)\t0.14002800840280097\n",
      "  (0, 8)\t0.14002800840280097\n",
      "  (0, 10)\t0.14002800840280097\n",
      "  (0, 0)\t0.14002800840280097\n",
      "  (0, 15)\t0.28005601680560194\n",
      "  (0, 9)\t0.14002800840280097\n",
      "  (0, 13)\t0.14002800840280097\n",
      "  (0, 21)\t0.14002800840280097\n",
      "  (0, 18)\t0.14002800840280097\n",
      "  (0, 2)\t0.14002800840280097\n",
      "  (0, 34)\t0.14002800840280097\n"
     ]
    }
   ],
   "source": [
    "tfid_out = vector.fit_transform(text) \n",
    "print(tfid_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adding' 'alone' 'amazon' 'and' 'as' 'but' 'can' 'competing' 'content'\n",
      " 'effort' 'engaging' 'for' 'get' 'great' 'if' 'in' 'interface' 'intuitive'\n",
      " 'is' 'it' 'lumped' 'making' 'membership' 'my' 'not' 'other' 'past' 'pay'\n",
      " 'prime' 'service' 'services' 'stand' 'streaming' 'the' 'think' 'ugly'\n",
      " 'weren' 'with' 'wouldn']\n"
     ]
    }
   ],
   "source": [
    "print(vector.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     adding     alone    amazon       and        as       but       can  \\\n",
      "0  0.140028  0.140028  0.140028  0.140028  0.280056  0.140028  0.140028   \n",
      "\n",
      "   competing   content    effort  ...   service  services     stand  \\\n",
      "0   0.140028  0.140028  0.140028  ...  0.140028  0.140028  0.140028   \n",
      "\n",
      "   streaming       the     think      ugly     weren      with    wouldn  \n",
      "0   0.140028  0.280056  0.140028  0.140028  0.140028  0.140028  0.140028  \n",
      "\n",
      "[1 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(tfid_out.todense(), columns=vector.get_feature_names_out()) \n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
